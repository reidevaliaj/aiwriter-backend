"""
OpenAI client singleton and helper functions.
"""
import json
import logging
from typing import List, Dict, Any, Optional
from openai import OpenAI
from .config import settings

logger = logging.getLogger(__name__)

# Singleton instance
_openai_client: Optional[OpenAI] = None


def get_openai() -> OpenAI:
    """Get OpenAI client singleton."""
    global _openai_client
    
    if _openai_client is None:
        if not settings.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY is required but not set")
        
        # Initialize OpenAI client with compatibility check
        try:
            _openai_client = OpenAI(
                api_key=settings.OPENAI_API_KEY,
                timeout=settings.OPENAI_TIMEOUT_S
            )
        except TypeError as e:
            if "unexpected keyword argument" in str(e):
                # Fallback for older OpenAI SDK versions
                logger.warning("Using fallback OpenAI client initialization (older SDK version)")
                _openai_client = OpenAI(api_key=settings.OPENAI_API_KEY)
            else:
                raise
        logger.info(f"OpenAI client initialized with model: {settings.OPENAI_TEXT_MODEL}")
    
    return _openai_client


async def run_text(messages: List[Dict[str, str]], **opts) -> str:
    """
    Generate text using OpenAI chat completions.
    
    Args:
        messages: List of message dicts with 'role' and 'content'
        **opts: Additional options (model, temperature, max_tokens, etc.)
    
    Returns:
        Generated text content
    """
    client = get_openai()
    
    # Default options with compatibility for newer models
    options = {
        "model": settings.OPENAI_TEXT_MODEL,
        "temperature": settings.OPENAI_TEMPERATURE,
        "messages": messages
    }
    
    # Use correct parameters based on model
    if settings.OPENAI_TEXT_MODEL == "gpt-5":
        # GPT-5 uses max_completion_tokens and supports new parameters
        options["max_completion_tokens"] = settings.OPENAI_MAX_TOKENS_TEXT
        options["verbosity"] = "low"  # GPT-5 specific parameter
        options["reasoning_effort"] = "medium"  # GPT-5 specific parameter
        # Remove temperature for GPT-5 as it's not supported
        options.pop("temperature", None)
    elif settings.OPENAI_TEXT_MODEL in ["gpt-4o", "gpt-4o-mini"]:
        # GPT-4o models use max_completion_tokens
        options["max_completion_tokens"] = settings.OPENAI_MAX_TOKENS_TEXT
    else:
        # Older models use max_tokens
        options["max_tokens"] = settings.OPENAI_MAX_TOKENS_TEXT
    
    # Override with any provided options
    options.update(opts)
    
    try:
        logger.info(f"Calling OpenAI with model: {options['model']}")
        logger.info(f"Using token parameter: {'max_completion_tokens' if 'max_completion_tokens' in options else 'max_tokens'}")
        if settings.OPENAI_TEXT_MODEL == "gpt-5":
            logger.info(f"GPT-5 parameters: verbosity={options.get('verbosity')}, reasoning_effort={options.get('reasoning_effort')}")
            logger.info(f"GPT-5: temperature removed (not supported)")
        
        response = client.chat.completions.create(**options)
        
        content = response.choices[0].message.content
        logger.info(f"OpenAI response received, length: {len(content) if content else 0}")
        
        return content or ""
        
    except Exception as e:
        logger.error(f"OpenAI text generation failed: {str(e)}")
        raise


async def gen_image(prompt: str, size: str = "1024x1024", quality: str = "high") -> str:
    """
    Generate image using OpenAI DALL-E.
    
    Args:
        prompt: Image generation prompt
        size: Image size (1024x1024, 1792x1024, 1024x1792)
        quality: Image quality (standard, hd)
    
    Returns:
        Image URL
    """
    client = get_openai()
    
    try:
        logger.info(f"Generating image with prompt: {prompt[:100]}...")
        response = client.images.generate(
            model=settings.OPENAI_IMAGE_MODEL,
            prompt=prompt,
            size=size,
            quality=quality,
            n=1
        )
        
        image_url = response.data[0].url
        logger.info(f"Image generated successfully: {image_url}")
        
        return image_url
        
    except Exception as e:
        logger.error(f"OpenAI image generation failed: {str(e)}")
        raise


def validate_json_response(content: str, context: str = "") -> Dict[str, Any]:
    """
    Validate and parse JSON response from OpenAI.
    
    Args:
        content: Raw content from OpenAI
        context: Context for error messages
    
    Returns:
        Parsed JSON dict
    
    Raises:
        ValueError: If JSON is invalid
    """
    try:
        # Try to find JSON in the content
        content = content.strip()
        
        # Look for JSON block markers
        if "```json" in content:
            start = content.find("```json") + 7
            end = content.find("```", start)
            if end != -1:
                content = content[start:end].strip()
        elif "```" in content:
            start = content.find("```") + 3
            end = content.find("```", start)
            if end != -1:
                content = content[start:end].strip()
        elif "<pre>" in content:
            # Handle <pre> tags (GPT-5 sometimes uses these)
            start = content.find("<pre>") + 5
            end = content.find("</pre>", start)
            if end != -1:
                content = content[start:end].strip()
        
        # Clean up any remaining HTML tags or extra whitespace
        content = content.replace('<pre>', '').replace('</pre>', '').strip()
        
        # Remove any leading/trailing whitespace and newlines
        content = content.strip()
        
        # If content is empty after cleaning, raise an error
        if not content:
            raise ValueError(f"Empty content after cleaning for {context}")
        
        # Parse JSON
        result = json.loads(content)
        logger.info(f"JSON validation successful for {context}")
        return result
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON validation failed for {context}: {str(e)}")
        logger.error(f"Content: {content[:200]}...")
        raise ValueError(f"Invalid JSON response for {context}: {str(e)}")


async def retry_with_json_prompt(messages: List[Dict[str, str]], context: str = "") -> Dict[str, Any]:
    """
    Retry OpenAI call with JSON-only prompt if first attempt fails.
    
    Args:
        messages: Original messages
        context: Context for error messages
    
    Returns:
        Parsed JSON dict
    """
    try:
        # First attempt
        content = await run_text(messages)
        return validate_json_response(content, context)
        
    except ValueError as e:
        # Retry with JSON-only prompt
        logger.info(f"Retrying with JSON-only prompt for {context}: {str(e)}")
        
        retry_messages = messages + [
            {
                "role": "user",
                "content": "Return valid JSON only. No commentary, no HTML tags, no explanations. Just the JSON object."
            }
        ]
        
        try:
            content = await run_text(retry_messages)
            return validate_json_response(content, f"{context} (retry)")
        except Exception as retry_error:
            logger.error(f"Retry failed for {context}: {str(retry_error)}")
            raise ValueError(f"Failed to get valid JSON for {context} after retry: {str(retry_error)}")
